{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.svcl.ucsd.edu/projects/anomaly/UCSD_Anomaly_Dataset.tar.gz\n",
    "!tar xzvf UCSD_Anomaly_Dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-layer-normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATASET_PATH =\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train\"\n",
    "    SINGLE_TEST_PATH = \"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/Test032\"\n",
    "    TESTSET_PATH = \"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/\"\n",
    "    BATCH_SIZE = 4\n",
    "    EPOCHS = 3\n",
    "    MODEL_PATH = \"model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shelve\n",
    "\n",
    "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
    "    clips = []\n",
    "    sz = len(frames_list)\n",
    "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
    "    cnt = 0\n",
    "    for start in range(0, stride):\n",
    "        for i in range(start, sz, stride):\n",
    "            clip[cnt, :, :, 0] = frames_list[i]\n",
    "            cnt = cnt + 1\n",
    "            if cnt == sequence_size:\n",
    "                clips.append(np.copy(clip))\n",
    "                cnt = 0\n",
    "    return clips\n",
    "\n",
    "\n",
    "def get_training_set(training_set_path):\n",
    "    clips = []\n",
    "    for folder in sorted(listdir(training_set_path)):\n",
    "        if isdir(join(Config.DATASET_PATH, folder)):\n",
    "            all_frames = []\n",
    "            for img_name in sorted(listdir(join(training_set_path, folder))):\n",
    "                if str(join(join(training_set_path, folder), img_name))[-3:] == \"tif\":\n",
    "                    img = Image.open(join(join(training_set_path, folder), img_name)).resize((256, 256))\n",
    "                    img = np.array(img, dtype=np.float32) / 256.0\n",
    "                    all_frames.append(img)\n",
    "            for stride in range(1, 3):\n",
    "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=10))\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "    grayValue = 0.07 * image[:,:,2] + 0.72 * image[:,:,1] + 0.21 * image[:,:,0]\n",
    "    gray_img = grayValue.astype(np.uint8)\n",
    "    return gray_img\n",
    "\n",
    "def get_local_training_set(training_set_path):\n",
    "    clips = []\n",
    "    clip = []\n",
    "    for image in listdir(training_set_path):\n",
    "        if str(join(join(training_set_path, image), image))[-3:] == \"tif\":\n",
    "            img = Image.open(join(training_set_path, image)).resize((256, 256))\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            img = grayscale(img)\n",
    "            img = img  / 256.0\n",
    "            clip.append(img)\n",
    "            if len(clip) == 10:\n",
    "                clips.append(clip)\n",
    "                clip = []\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "def get_model(reload_model=True, training_sets_paths = []):\n",
    "    if not reload_model:\n",
    "        loaded_model =  load_model(Config.MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
    "        if len(training_sets_paths) != 0:\n",
    "            for training_set_path in training_sets_paths:\n",
    "                if training_set_path[0:4] == \"CCTV\":\n",
    "                    training_set = get_local_training_set(training_set_path)\n",
    "                else:\n",
    "                    training_set = get_training_set(training_set_path)\n",
    "                training_set = np.array(training_set)\n",
    "                training_set = training_set.reshape(-1,10,256,256,1)\n",
    "                loaded_model.fit(training_set, training_set,\n",
    "                        batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
    "                loaded_model.save(Config.MODEL_PATH)\n",
    "        return loaded_model\n",
    "        \n",
    "    training_set = get_training_set(training_sets_paths[0])\n",
    "    training_set = np.array(training_set)\n",
    "    training_set = training_set.reshape(-1,10,256,256,1)\n",
    "    seq = Sequential()\n",
    "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    # # # # #\n",
    "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
    "    seq.add(LayerNormalization())\n",
    "    # # # # #\n",
    "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
    "    seq.add(LayerNormalization())\n",
    "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
    "    print(seq.summary())\n",
    "    seq.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
    "    seq.fit(training_set, training_set,\n",
    "            batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
    "    seq.save(Config.MODEL_PATH)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on local data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_on_local_data():\n",
    "    get_model(False, training_sets_paths = [\"CCTV/train_tiff_frames\"])\n",
    "\n",
    "train_model_on_local_data()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all train data, process it, and put it in 1 DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set_no_aug(training_set_path):\n",
    "    clips = []\n",
    "    clip = []\n",
    "    for folder in sorted(listdir(training_set_path)):\n",
    "        if isdir(join(Config.DATASET_PATH, folder)):\n",
    "            all_frames = []\n",
    "            for img_name in sorted(listdir(join(training_set_path, folder))):\n",
    "                if str(join(join(training_set_path, folder), img_name))[-3:] == \"tif\":\n",
    "                    img = Image.open(join(join(training_set_path, folder), img_name)).resize((256, 256))\n",
    "                    img = np.array(img, dtype=np.float32) / 256.0\n",
    "                    clip.append(img)\n",
    "                    if len(clip) == 10:\n",
    "                        clips.append(clip)\n",
    "                        clip = []\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_training_set_no_aug(\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train\")\n",
    "train_set.extend(get_training_set_no_aug(\"UCSD_Anomaly_Dataset.v1p2/UCSDped2/Train\"))\n",
    "train_set.extend(get_local_training_set(\"CCTV/train_tiff_frames\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_difference_images(train_set):\n",
    "    model = get_model(False, [])\n",
    "\n",
    "    sequences = train_set\n",
    "    sequences = np.array(sequences).reshape(-1, 10, 256, 256, 1)\n",
    "    \n",
    "    reconstructed_sequences = model.predict(sequences,batch_size=4)\n",
    "\n",
    "    test_mae_loss = np.mean(np.abs(reconstructed_sequences - sequences), axis=(2,3,4))\n",
    "    return np.abs(reconstructed_sequences - sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diff_images = get_train_difference_images(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_err = train_diff_images\n",
    "model_mse = np.mean((model_err) ** 2, axis=(2, 3, 4))\n",
    "model_p_50 = np.percentile((model_err) ** 2, 50, axis=(2, 3, 4))\n",
    "model_p_75 = np.percentile((model_err) ** 2, 75, axis=(2, 3, 4))\n",
    "model_p_90 = np.percentile((model_err) ** 2, 90, axis=(2, 3, 4))\n",
    "model_p_95 = np.percentile((model_err) ** 2, 95, axis=(2, 3, 4))\n",
    "model_p_99 = np.percentile((model_err) ** 2, 99, axis=(2, 3, 4))\n",
    "model_std = np.std((model_err) ** 2, axis=(2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mse = np.reshape(model_mse, np.prod(model_mse.shape))\n",
    "model_p_50 = np.reshape(model_p_50, np.prod(model_mse.shape))\n",
    "model_p_75 = np.reshape(model_p_75, np.prod(model_mse.shape))\n",
    "model_p_90 = np.reshape(model_p_90, np.prod(model_mse.shape))\n",
    "model_p_95 = np.reshape(model_p_95, np.prod(model_mse.shape))\n",
    "model_p_99 = np.reshape(model_p_99, np.prod(model_mse.shape))\n",
    "model_std = np.reshape(model_std, np.prod(model_mse.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(\n",
    "    {\n",
    "        \"model_mse\": model_mse,\n",
    "        \"model_p_50\": model_p_50,\n",
    "        \"model_p_75\": model_p_75,\n",
    "        \"model_p_90\": model_p_90,\n",
    "        \"model_p_95\": model_p_95,\n",
    "        \"model_p_99\": model_p_99,\n",
    "        \"model_std\": model_std\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_mse</th>\n",
       "      <th>model_p_50</th>\n",
       "      <th>model_p_75</th>\n",
       "      <th>model_p_90</th>\n",
       "      <th>model_p_95</th>\n",
       "      <th>model_p_99</th>\n",
       "      <th>model_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18790.000000</td>\n",
       "      <td>18790.000000</td>\n",
       "      <td>18790.000000</td>\n",
       "      <td>18790.000000</td>\n",
       "      <td>18790.000000</td>\n",
       "      <td>18790.000000</td>\n",
       "      <td>18790.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>0.005771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.020984</td>\n",
       "      <td>0.004277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.002020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.012562</td>\n",
       "      <td>0.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.014867</td>\n",
       "      <td>0.043464</td>\n",
       "      <td>0.008766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.043187</td>\n",
       "      <td>0.124936</td>\n",
       "      <td>0.024656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_mse    model_p_50    model_p_75    model_p_90    model_p_95  \\\n",
       "count  18790.000000  18790.000000  18790.000000  18790.000000  18790.000000   \n",
       "mean       0.002157      0.000487      0.001682      0.004975      0.009676   \n",
       "std        0.001522      0.000313      0.001087      0.003494      0.007049   \n",
       "min        0.000758      0.000177      0.000656      0.001864      0.003391   \n",
       "25%        0.000819      0.000196      0.000721      0.002029      0.003648   \n",
       "50%        0.001067      0.000245      0.000927      0.002633      0.004681   \n",
       "75%        0.003336      0.000781      0.002553      0.007631      0.014867   \n",
       "max        0.008554      0.001589      0.006469      0.021376      0.043187   \n",
       "\n",
       "         model_p_99     model_std  \n",
       "count  18790.000000  18790.000000  \n",
       "mean       0.028099      0.005771  \n",
       "std        0.020984      0.004277  \n",
       "min        0.008646      0.001841  \n",
       "25%        0.009509      0.002020  \n",
       "50%        0.012562      0.003458  \n",
       "75%        0.043464      0.008766  \n",
       "max        0.124936      0.024656  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.to_pickle(\"allHybridTrainErrorDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all test data, process it, and put it in 1 DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_test(single_test_path):\n",
    "    sz = 200\n",
    "    test = np.zeros(shape=(sz, 256, 256, 1))\n",
    "    cnt = 0\n",
    "    for f in sorted(listdir(single_test_path)):\n",
    "        if str(join(single_test_path, f))[-3:] == \"tif\":\n",
    "            img = Image.open(join(single_test_path, f)).resize((256, 256))\n",
    "            img = np.array(img, dtype=np.float32) / 256.0\n",
    "            test[cnt, :, :, 0] = img\n",
    "            cnt = cnt + 1\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tests(test_sets_paths):\n",
    "    tests = []\n",
    "    clip = []\n",
    "    for test_set_path in test_sets_paths:\n",
    "        for folder in sorted(listdir(test_set_path)):\n",
    "            if isdir(join(test_set_path, folder)) and folder[-3:]!=\"_gt\" and folder!=\"Test017\" and folder[0]!='.':\n",
    "                print(folder)\n",
    "                single_test_path = join(test_set_path, folder)\n",
    "                tests.append(get_single_test(single_test_path))\n",
    "    print(len(tests))\n",
    "    tests = np.array(tests).reshape(-1, 10, 256, 256, 1)\n",
    "    print(tests.shape)\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image):\n",
    "    grayValue = 0.07 * image[:,:,2] + 0.72 * image[:,:,1] + 0.21 * image[:,:,0]\n",
    "    gray_img = grayValue.astype(np.uint8)\n",
    "    return gray_img.reshape(image.shape[0], image.shape[1], 1)\n",
    "\n",
    "def get_all_local_tests(test_set_paths):\n",
    "    clips = []\n",
    "    clip = []\n",
    "\n",
    "    for test_set_path in test_set_paths:\n",
    "        for image in listdir(test_set_path):\n",
    "            if str(join(join(test_set_path, image), image))[-3:] == \"tif\":\n",
    "                # resize all images\n",
    "                img = Image.open(join(test_set_path, image)).resize((256, 256))\n",
    "                # normalize images\n",
    "                img = np.array(img, dtype=np.float32)\n",
    "                img = grayscale(img)\n",
    "                img = img  / 256.0\n",
    "                clip.append(img)\n",
    "                if len(clip) == 10:\n",
    "                    clips.append(clip)\n",
    "                    clip = []\n",
    "                \n",
    "    clips = np.array(clips).reshape(-1, 10, 256, 256, 1)\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_difference_images(test_set):\n",
    "    model = get_model(False) #False\n",
    "\n",
    "    sequences = test_set\n",
    "\n",
    "    reconstructed_sequences = model.predict(sequences,batch_size=4)\n",
    "\n",
    "    test_mae_loss = np.mean(np.abs(reconstructed_sequences - sequences), axis=(2,3,4))\n",
    "\n",
    "    return np.abs(reconstructed_sequences - sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_all_tests([\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/\", \"UCSD_Anomaly_Dataset.v1p2/UCSDped2/Test/\"])\n",
    "local_test_set = get_all_local_tests([\"CCTV/test_tiff_frames\", \"CCTV/test_tiff_frames_2\"])\n",
    "test_set = np.concatenate((test_set, local_test_set), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_diff_images = get_test_difference_images(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_err = test_diff_images\n",
    "model_mse = np.mean((model_err) ** 2, axis=(2, 3, 4))\n",
    "model_p_50 = np.percentile((model_err) ** 2, 50, axis=(2, 3, 4))\n",
    "model_p_75 = np.percentile((model_err) ** 2, 75, axis=(2, 3, 4))\n",
    "model_p_90 = np.percentile((model_err) ** 2, 90, axis=(2, 3, 4))\n",
    "model_p_95 = np.percentile((model_err) ** 2, 95, axis=(2, 3, 4))\n",
    "model_p_99 = np.percentile((model_err) ** 2, 99, axis=(2, 3, 4))\n",
    "model_std = np.std((model_err) ** 2, axis=(2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mse = np.reshape(model_mse, np.prod(model_mse.shape))\n",
    "model_p_50 = np.reshape(model_p_50, np.prod(model_mse.shape))\n",
    "model_p_75 = np.reshape(model_p_75, np.prod(model_mse.shape))\n",
    "model_p_90 = np.reshape(model_p_90, np.prod(model_mse.shape))\n",
    "model_p_95 = np.reshape(model_p_95, np.prod(model_mse.shape))\n",
    "model_p_99 = np.reshape(model_p_99, np.prod(model_mse.shape))\n",
    "model_std = np.reshape(model_std, np.prod(model_mse.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {\n",
    "        \"model_mse\": model_mse,\n",
    "        \"model_p_50\": model_p_50,\n",
    "        \"model_p_75\": model_p_75,\n",
    "        \"model_p_90\": model_p_90,\n",
    "        \"model_p_95\": model_p_95,\n",
    "        \"model_p_99\": model_p_99,\n",
    "        \"model_std\": model_std\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_mse</th>\n",
       "      <th>model_p_50</th>\n",
       "      <th>model_p_75</th>\n",
       "      <th>model_p_90</th>\n",
       "      <th>model_p_95</th>\n",
       "      <th>model_p_99</th>\n",
       "      <th>model_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16220.000000</td>\n",
       "      <td>16220.000000</td>\n",
       "      <td>16220.000000</td>\n",
       "      <td>16220.000000</td>\n",
       "      <td>16220.000000</td>\n",
       "      <td>16220.000000</td>\n",
       "      <td>16220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.013674</td>\n",
       "      <td>0.039973</td>\n",
       "      <td>0.008410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.021856</td>\n",
       "      <td>0.004448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>0.001911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>0.004468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.014149</td>\n",
       "      <td>0.042433</td>\n",
       "      <td>0.008473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.018571</td>\n",
       "      <td>0.054170</td>\n",
       "      <td>0.011090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.045361</td>\n",
       "      <td>0.097691</td>\n",
       "      <td>0.245799</td>\n",
       "      <td>0.044391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_mse    model_p_50    model_p_75    model_p_90    model_p_95  \\\n",
       "count  16220.000000  16220.000000  16220.000000  16220.000000  16220.000000   \n",
       "mean       0.003012      0.000628      0.002219      0.006905      0.013674   \n",
       "std        0.001548      0.000364      0.001136      0.003540      0.007193   \n",
       "min        0.000784      0.000180      0.000679      0.001922      0.003483   \n",
       "25%        0.001480      0.000255      0.001061      0.003513      0.006818   \n",
       "50%        0.003166      0.000618      0.002300      0.007066      0.014149   \n",
       "75%        0.004080      0.000895      0.003075      0.009287      0.018571   \n",
       "max        0.016757      0.001878      0.007952      0.045361      0.097691   \n",
       "\n",
       "         model_p_99     model_std  \n",
       "count  16220.000000  16220.000000  \n",
       "mean       0.039973      0.008410  \n",
       "std        0.021856      0.004448  \n",
       "min        0.008980      0.001911  \n",
       "25%        0.019726      0.004468  \n",
       "50%        0.042433      0.008473  \n",
       "75%        0.054170      0.011090  \n",
       "max        0.245799      0.044391  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.to_pickle(\"allHybridTestErrorDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalous frames classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"allHybridTrainErrorDF\")\n",
    "test_df = pd.read_pickle(\"allHybridTestErrorDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests_labels(file_name):\n",
    "    f = open(file_name, \"r\")\n",
    "    lines = f.readlines()\n",
    "    labels = []\n",
    "    index = 0\n",
    "    for line in lines:\n",
    "        open_bracket = line.find('[')\n",
    "        close_bracket = line.find(']')\n",
    "        if (open_bracket != -1 and close_bracket != -1):\n",
    "            index = index + 1\n",
    "            if index == 16:\n",
    "                continue\n",
    "            temp = 0\n",
    "            video_labels = []\n",
    "            for i in range(open_bracket+1, close_bracket+1):\n",
    "                if line[i] == ':' or line[i] == ',' or line[i] == ']':\n",
    "                    video_labels.append(temp)\n",
    "                    temp = 0\n",
    "                elif line[i] == ' ':\n",
    "                    continue\n",
    "                else:\n",
    "                    temp = temp * 10 + (ord(line[i])-ord('0'))\n",
    "\n",
    "            labels.append(video_labels)\n",
    "    print(len(labels))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests_frames_labels():\n",
    "    labels_files = [\"UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/UCSDped1.m\", \"UCSD_Anomaly_Dataset.v1p2/UCSDped2/Test/UCSDped2.m\"]\n",
    "    labels = []\n",
    "    for label_file in labels_files:\n",
    "        labels.extend(get_tests_labels(label_file))\n",
    "    frames_labels = np.ones(len(labels)*200)\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        label = labels[i]\n",
    "        for jj in range(0, len(label), 2):\n",
    "            start = label[jj]-1 + i * 200\n",
    "            end = label[jj+1] + i * 200\n",
    "            for j in range(start, end):\n",
    "                frames_labels[j] = -1\n",
    "        \n",
    "    return frames_labels\n",
    "\n",
    "# -1 means anomaly\n",
    "true_labels = get_tests_frames_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local CCTV videos labels are put manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_test_1_true_labels = np.ones(3260) * -1 #3260 is the number of local test frames\n",
    "\n",
    "for i in range(1000): #560\n",
    "    local_test_1_true_labels[i] = 1\n",
    "\n",
    "local_test_2_true_labels = np.ones(3560) * -1 #3560 is the number of local test frames\n",
    "\n",
    "for i in range(1031): #1410\n",
    "    local_test_2_true_labels[i] = 1\n",
    "\n",
    "local_test_true_labels = np.concatenate((local_test_1_true_labels, local_test_2_true_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.concatenate((true_labels, local_test_true_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.OneClassSVM(nu=0.04, gamma = 0.001, kernel='rbf') \n",
    "model.fit(train_df)\n",
    "test_labels = model.predict(test_df) \n",
    "\n",
    "# 1 is anomaly\n",
    "true_labels2 = []\n",
    "for i in true_labels:\n",
    "    true_labels2.append(1 if i==-1 else 0)\n",
    "    \n",
    "test_labels2 = []\n",
    "for i in test_labels:\n",
    "    test_labels2.append(1 if i==-1 else 0)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(confusion_matrix(true_labels2, test_labels2))\n",
    "print(accuracy_score(true_labels2, test_labels2))\n",
    "print(precision_score(true_labels2, test_labels2))\n",
    "print(recall_score(true_labels2, test_labels2))\n",
    "print(f1_score(true_labels2, test_labels2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
